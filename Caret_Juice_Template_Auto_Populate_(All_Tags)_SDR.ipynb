{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "To use this, you will need to make a copy of this template so that you can edit where needed.\n",
        "\n",
        "This is meant to run with an SDR template in Google Sheets. You will need to create a sheet, paste the URL of that sheet in the Variables section below and then select **Run All** in the Runtime dropdown in the primary navigation.\n",
        "\n",
        "You will then need to manually upload an export of your GTM container in **Upload File** section.\n",
        "\n",
        "Finally, you will need to give permissions for this notebook to make changes to Google Sheets in the **Authenticate** section.\n",
        "\n",
        "Once that is done, this notebook will populate the Tags, Triggers, and Variables sections of the SDR template with no further action on your part.\n",
        "\n",
        "This script completely replaces the text on those tabs.\n",
        "\n",
        "GTM notes get copied to the Description columns. "
      ],
      "metadata": {
        "id": "-3SFB3QhD_vv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Variables**\n",
        "\n",
        "You will need to set these variables for this iPython notebook to work."
      ],
      "metadata": {
        "id": "F3kdwIgNBmCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spreadsheet = ''  # using the connect by URL method so put the full URL of the sheet that you are using for the SDR\n",
        "\n",
        "# Configure which sheet tabs to place the data\n",
        "# These tabs must exist in the SDR\n",
        "tag_worksheet = 'Tags'\n",
        "trigger_worksheet = 'Triggers'\n",
        "variable_worksheet = 'Variables'\n",
        "\n",
        "# Number of header rows to skip\n",
        "header_rows = 5\n",
        "\n"
      ],
      "metadata": {
        "id": "Jtz1qaHXBi4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Upload File**\n",
        "\n",
        "Export the GTM Container under Admin > Export Container and upload the JSON File."
      ],
      "metadata": {
        "id": "dSQ-a-zH7API"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRHVlbzc6twz"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Authenticate**\n",
        "\n",
        "This will open a new window where you need to log in to Google Accounts, give this Colab permission to access Drive, copy the key that gets generated after giving permission, and finally paste that key back here and complete the authentication.\n",
        "\n",
        "*2022-04-19: Updated authentication method*"
      ],
      "metadata": {
        "id": "7QmdTaXEM2hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# authenticate\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "gc = gspread.authorize(creds)"
      ],
      "metadata": {
        "id": "3nsT00AI7fTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Utilities** \n",
        "\n",
        "Utility functions that we are going to re-use later."
      ],
      "metadata": {
        "id": "LgnsCCdvDmrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install -U 'fsspec[s3]'\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import re\n",
        "\n",
        "uploaded_json = list(uploaded.values())[0]\n",
        "container = json.loads(uploaded_json.decode('utf-8'))\n",
        "\n",
        "json_tags = container['containerVersion']['tag']\n",
        "json_triggers = container['containerVersion']['trigger']\n",
        "json_folders = container['containerVersion']['folder']\n",
        "json_variables = container['containerVersion']['variable']\n",
        "\n",
        "def trigger_lookup(trigger_id_list):\n",
        "  triggers = ''\n",
        "  for trigger in json_triggers:\n",
        "    for id in trigger_id_list:\n",
        "      if id == trigger['triggerId']:\n",
        "        triggers = triggers + trigger['name'] + ';'\n",
        "  return triggers[:-1] #remove the last semi-colon\n",
        "\n",
        "def folder_lookup(folder_id):\n",
        "  name = 'not found'\n",
        "  for folder in json_folders:\n",
        "    if folder['folderId'] == folder_id:\n",
        "      name = folder['name']\n",
        "  return name\n",
        "\n",
        "def list_tags_matching_trigger(trigger_type, trigger_id):\n",
        "  tags = ''\n",
        "  for tag in json_tags:\n",
        "    if trigger_type in tag:\n",
        "      if trigger_id in tag[trigger_type]: \n",
        "        tags = tags + tag['name'] + '; '\n",
        "  return tags[:-2]\n",
        "\n",
        "\n",
        "def timestamp_from_fingerprint(fingerprint):\n",
        "  ts = datetime.fromtimestamp(int(fingerprint[:-3] ))\n",
        "  return ts\n",
        "\n",
        "def is_ga4_trigger( trigger_id ):\n",
        "  is_ga4 = False\n",
        "  for tag in json_tags:\n",
        "    if (tag['type'] == 'gaawe' and trigger_id in tag['firingTriggerId']):\n",
        "      is_ga4 = True \n",
        "  return is_ga4\n",
        "\n",
        "def is_ga4_var( variable_name ):\n",
        "  is_ga4 = False\n",
        "  pattern = \"{{\" + variable_name + \"}}\"\n",
        "  for tag in json_tags:\n",
        "    if (tag['type'] == 'gaawe' and re.search(pattern, json.dumps(tag))):\n",
        "      is_ga4 = True \n",
        "  return is_ga4\n",
        "\n",
        "# do not use\n",
        "def container_lookup(container_id):\n",
        "  json_containers =  container['containerVersion']\n",
        "  for container in json_containers:\n",
        "    if container['containerId'] ==  container_id:\n",
        "      return container['name']\n",
        "    else:\n",
        "      return container['containerId']"
      ],
      "metadata": {
        "id": "K2j_SYEGDlaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parse the Tags**\n",
        "\n",
        "Drill down into the tag section of the JSON export. For each tag, find the values that correspond to the various columns in the spreadsheet.\n",
        "\n",
        "Save the tag data to a dataframe and list the first five entries."
      ],
      "metadata": {
        "id": "GdjnNZ5N7Jh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tags = []\n",
        "\n",
        "for tag in json_tags:\n",
        "  row = {}\n",
        "  row['ID'] = str(tag['tagId'])\n",
        "  row['Name'] = str(tag['name'])\n",
        "  row['Event Name'] = ''\n",
        "  if 'parameter' in tag:\n",
        "    for parameter in tag['parameter']:\n",
        "      if (parameter['key'] == 'eventName' and 'value' in parameter):\n",
        "        row['Event Name'] = parameter['value']\n",
        "  row['Type'] =  str(tag['type'])\n",
        "  if 'firingTriggerId' in tag:\n",
        "    row['Firing Triggers'] = trigger_lookup(tag['firingTriggerId'])\n",
        "  else: \n",
        "    row['Firing Triggers'] = 'none'\n",
        "  if 'blockingTriggerId' in tag:\n",
        "    row['Blocking Triggers'] =  trigger_lookup(tag['blockingTriggerId'])\n",
        "  else: \n",
        "    row['Blocking Triggers'] = 'none'\n",
        "  if 'parentFolderId' in tag:\n",
        "    row['Parent Folder'] = folder_lookup(tag['parentFolderId'])\n",
        "  else: \n",
        "    row['Parent Folder'] = 'none'\n",
        "  row['Last Edit'] = timestamp_from_fingerprint(tag['fingerprint'])\n",
        "  if 'paused' in tag:\n",
        "    row['Paused'] = 'true'\n",
        "  else: \n",
        "    row['Paused'] = 'false'\n",
        "  row['Container'] = tag['containerId']\n",
        "  row['Action'] = 'Review' # resetting the Action column because tags unlikely to match\n",
        "  if 'notes' in tag:\n",
        "    row['Description'] = tag['notes']\n",
        "  else:\n",
        "    row['Description'] = \"\"\n",
        "\n",
        "  tags.append(row)\n",
        "\n",
        "tag_data = pd.DataFrame(tags)\n",
        "tag_data.head()"
      ],
      "metadata": {
        "id": "a64bnsYddP7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save to Google Sheets**\n",
        "\n",
        "The will save as a GSheet in your Google Drive with the title of \"GTM Tags for GTM-CONTAINERID.\" It will take a few minutes for the data to fully populate in the sheet so be patient."
      ],
      "metadata": {
        "id": "hYzXGtEVNZS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gspread_dataframe import set_with_dataframe\n",
        "\n",
        "ss = gc.open_by_url(spreadsheet)\n",
        "ws = ss.worksheet(tag_worksheet)\n",
        "\n",
        "#delete existing data\n",
        "ws.clear()\n",
        "set_with_dataframe(ws, tag_data, row=header_rows )\n",
        "#restore the header text\n",
        "ws.update('B3', 'Tags')"
      ],
      "metadata": {
        "id": "zF7SsjXXv5Gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parse the Triggers**\n",
        "\n",
        "Since the JSON export maps tags to triggers but not the reverse, we loop through all of the triggers and then for each trigger loop through all of the tags to get the tag names."
      ],
      "metadata": {
        "id": "7fLjuLkPbqC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "triggers = []\n",
        "\n",
        "for trigger in json_triggers:\n",
        "  row = {}\n",
        "  row['ID'] = str(trigger['triggerId'])\n",
        "  row['Name'] = str(trigger['name'])\n",
        "  row['Type'] =  str(trigger['type'])\n",
        "  if 'filter' in trigger:\n",
        "    row['Filter'] = str(trigger['filter'])\n",
        "  else:\n",
        "    row['Filter'] = 'none'\n",
        "  if 'parentFolderId' in trigger:\n",
        "    row['Parent Folder'] = folder_lookup(trigger['parentFolderId'])\n",
        "  else: \n",
        "    row['Parent Folder'] = 'none'\n",
        "  row['Firing Tags'] = list_tags_matching_trigger('firingTriggerId',trigger['triggerId']  );\n",
        "  row['Blocking Tags'] = list_tags_matching_trigger('blockingTriggerId',trigger['triggerId']  );\n",
        "  row['Last Edit'] = timestamp_from_fingerprint(trigger['fingerprint'])\n",
        "  row['Action'] = 'Review' # resetting the Action column because tags unlikely to match\n",
        "  row['Container'] = trigger['containerId']\n",
        "  if 'notes' in trigger:\n",
        "    row['Description'] = trigger['notes']\n",
        "  else:\n",
        "    row['Description'] = ''\n",
        "\n",
        "  triggers.append(row)\n",
        "\n",
        "trigger_data = pd.DataFrame(triggers)\n",
        "trigger_data.head()"
      ],
      "metadata": {
        "id": "Rc3weUy3bs4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save to Google Sheets"
      ],
      "metadata": {
        "id": "8plpJk-ybuOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = ss.worksheet(trigger_worksheet)\n",
        "\n",
        "#delete existing data\n",
        "ws.clear()\n",
        "set_with_dataframe(ws, trigger_data, row=header_rows )\n",
        "#restore the header text\n",
        "ws.update('B3', 'Triggers')"
      ],
      "metadata": {
        "id": "Y5Smi89lbw4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parse the Variables"
      ],
      "metadata": {
        "id": "bK16LuzjbxL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variables = []\n",
        "\n",
        "\n",
        "for var in json_variables:\n",
        "  row = {}\n",
        "  row['ID'] = str(var['variableId'])\n",
        "  row['Name'] = str(var['name'])\n",
        "  row['Type'] =  str(var['type'])\n",
        "  if 'parentFolderId' in var:\n",
        "    row['Parent Folder'] = folder_lookup(var['parentFolderId'])\n",
        "  else: \n",
        "    row['Parent Folder'] = 'none'\n",
        "  row['Last Edit'] = timestamp_from_fingerprint(var['fingerprint'])\n",
        "  row['Action'] = 'Review' # resetting the Action column because tags unlikely to match\n",
        "  if 'notes' in var:\n",
        "    row['Description'] = var['notes']\n",
        "  else:\n",
        "    row['Description'] = \"\"\n",
        "\n",
        "  variables.append(row)\n",
        "\n",
        "variable_data = pd.DataFrame(variables)\n",
        "variable_data.head()"
      ],
      "metadata": {
        "id": "01Sv-aA6bywo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save to Google Sheets"
      ],
      "metadata": {
        "id": "afSqkOkTbzRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = ss.worksheet(variable_worksheet)\n",
        "\n",
        "#delete existing data\n",
        "ws.clear()\n",
        "set_with_dataframe(ws, variable_data, row=header_rows )\n",
        "#restore the header text\n",
        "ws.update('B3', 'Variables')"
      ],
      "metadata": {
        "id": "I20nAGv_b0_5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}